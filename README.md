Here's a **Markdown (`.md`)** project description for your **"Army Aircraft Detection"** system, based on the research paper you've uploaded: *"Advancing Real-Time Military Aircraft Detection: A Comprehensive Comparative Benchmark of Object Detection Frameworks"*.

---

# ğŸ›« Army Aircraft Detection Using Deep Learning

## ğŸ§  Project Overview

This project focuses on developing an **AI-powered detection system** to identify and localize **military aircraft** in real-time from aerial imagery. It leverages state-of-the-art **deep learning and transformer-based object detection models** such as **YOLOv10**, **YOLOv8**, **YOLOv7**, and **RT-DETR**, evaluated on a specialized dataset containing 81 types of military aircraft.

The goal is to provide high-accuracy, low-latency detection capabilities for applications like:
- Air defense systems
- Battlefield surveillance
- Intelligence gathering
- Drone-based reconnaissance

The study compares performance across key metrics including **mAP@0.5**, **inference speed**, and **model efficiency**, helping guide deployment decisions for different mission requirements.

---

## ğŸ¯ Objectives

1. Detect and classify various types of military aircraft from aerial images.
2. Compare the performance of CNN-based and Transformer-based models.
3. Achieve **real-time inference** suitable for tactical operations.
4. Evaluate model robustness under challenging conditions (e.g., camouflage, lighting variation).
5. Provide interpretable results for situational awareness and decision-making.

---

## ğŸ“ Dataset

### Military Aircraft Detection Dataset (MADD)

- Contains **12,008 high-resolution RGB images**
- Includes **19,270 labeled aircraft instances**
- Covers **43+ distinct aircraft types** (e.g., F-16, F-35, Su-57, B-2)
- Annotations in **PASCAL-VOC XML format**
- Images sourced from public repositories (Wikimedia Commons, Google Images)

> The dataset includes variations in:
> - Orientation
> - Lighting
> - Scale
> - Environmental conditions
> - Partial occlusion

---

## ğŸ§° Technologies Used

- **Python 3.x**
- **YOLOv10 / YOLOv8 / YOLOv7**: For real-time object detection
- **RT-DETR / RT-DETRv3**: Transformer-based real-time detection
- **OpenCV**: For image preprocessing
- **PyTorch / PaddlePaddle**: Model frameworks
- **Ultralytics YOLO Suite** and **PaddleDetection Toolkit**
- **Matplotlib / Seaborn**: For visualization
- **Streamlit / Flask (optional)**: For web interface

---

## ğŸ”¬ Methodology

### Step 1: Data Preprocessing

- Resize images to model-specific resolutions:
  - YOLOv10: `512Ã—512`
  - YOLOv8/RT-DETR: `640Ã—640`
- Normalize pixel values to `[0, 1]`
- Apply data augmentation techniques:
  - Horizontal flipping
  - Brightness adjustment (Â±20%)
  - Rotation (Â±15Â°)
  - Mosaic augmentation (for YOLO variants)
  - CutOut for partial visibility simulation

### Step 2: Model Training

All models were trained using the same protocol for fair comparison:

- **Training split**: 70% train, 15% validation, 15% test
- **Optimizer**: SGD with momentum (0.9), weight decay (0.0005)
- **Learning rate**: Cyclic cosine-decay starting at 0.01
- **Batch size**: 16 across 4x NVIDIA A100 GPUs
- **Mixed precision training** via PyTorch AMP module
- **Epochs**: 100 (with early stopping)

### Step 3: Model Evaluation

Key evaluation metrics used:

| Metric | Description |
|--------|-------------|
| **mAP@0.5** | Mean Average Precision at IoU threshold of 0.5 |
| **Precision** | TP / (TP + FP) |
| **Recall** | TP / (TP + FN) |
| **Inference Time (ms)** | Speed per image |
| **Model Size (Params)** | Number of trainable parameters |
| **Computational Load (GFLOPs)** | Floating point operations per second |

---

## ğŸ§ª Results Summary

| Model | Parameters (M) | GFLOPs | Inference (ms) | mAP@0.5 (%) | Recall (%) |
|-------|----------------|--------|----------------|-------------|------------|
| **RT-DETR** | 32.4 | 11.2 | 45.3 | 92.7 | 90.4 |
| **RT-DETRv3** | 35.6 | 12.5 | 47.8 | **94.6** | **92.1** |
| **YOLOv7** | 36.9 | 9.8 | 27.8 | 90.2 | 82.7 |
| **YOLOv8** | 43.7 | 13.5 | 32.5 | 94.0 | 88.1 |
| **YOLOv10** | 41.2 | 8.7 | **10.7** | 94.4 | 89.5 |

### Key Findings

- **RT-DETRv3** achieved the highest **mAP@0.5** (94.6%) due to its hierarchical dense positive supervision method.
- **YOLOv10** showed **best inference speed** at only **10.7 ms/image**, making it ideal for time-sensitive missions.
- All models performed better on **fighter jets and bombers** compared to **transport planes, helicopters, and reconnaissance aircraft**, likely due to more distinctive visual features.
- Statistical analysis confirmed that differences between top models are **not always significant**, suggesting both **YOLOv8 and YOLOv10** are viable options depending on application needs.

---

## ğŸš€ Future Work

1. **Domain Adaptation**: Improve performance on camouflaged or low-visibility aircraft using domain-specific augmentations.
2. **Edge Deployment**: Optimize models for edge devices using quantization or pruning.
3. **Multi-Sensor Integration**: Combine radar and infrared inputs with visual detection.
4. **Explainability**: Use Grad-CAM or SHAP to visualize attention regions for operator trust.
5. **Real-Time Video Processing**: Extend to drone feeds or satellite video streams.

---

## ğŸ“¦ Folder Structure

```
army-aircraft-detection/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ MADD/               # Military Aircraft Detection Dataset
â”‚       â”œâ”€â”€ images/
â”‚       â””â”€â”€ labels/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ yolov10/
â”‚   â”œâ”€â”€ yolov8/
â”‚   â”œâ”€â”€ yolov7/
â”‚   â””â”€â”€ rtdetr/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploratory_analysis.ipynb
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ demo_app.py          # Optional Streamlit/Flask app
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ“š References

1. Redmon et al. â€“ *You Only Look Once (YOLO)* series
2. Ultralytics â€“ [YOLOv8 Documentation](https://docs.ultralytics.com/)
3. Baidu Inc. â€“ *RT-DETR: Real-Time Detection Transformer*
4. Wang et al. â€“ *RT-DETRv3: Hierarchical Dense Positive Supervision*
5. Research Paper Source: *"Advancing Real-Time Military Aircraft Detection..."*

---

## âœ… License

MIT License â€“ see `LICENSE` for details.

> âš ï¸ This project is intended for educational and research purposes only. Always ensure ethical use of AI in defense applications.

---

Would you like me to:
- Generate the full Python script (`detect_aircraft.py`)?
- Include a Jupyter Notebook version?
- Provide instructions for deploying this as a web app?

Let me know how I can assist further! ğŸ˜Š
